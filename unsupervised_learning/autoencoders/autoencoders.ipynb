{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"Task 3: Variational Autoencoder\"\"\"\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "\n",
    "def autoencoder(input_dims, hidden_layers, latent_dims):\n",
    "    \"\"\"Creates a variational autoencoder\n",
    "    Args:\n",
    "        input_dims (int): Contains the dimensions of the model input\n",
    "        hidden_layers (list): Contains the number of nodes for each hidden\n",
    "            layer; the hidden layers should be reversed for the decoder\n",
    "        latent_dims (int): Contains the dimensions of the latent space\n",
    "    Returns:\n",
    "        encoder, decoder, auto (tuple): Contains the encoder, decoder and\n",
    "            autoencoder models, respectively\"\"\"\n",
    "\n",
    "\n",
    "    # Encoder\n",
    "    encoder_inputs = keras.Input(shape=(input_dims,))\n",
    "    x = encoder_inputs\n",
    "\n",
    "    for units in hidden_layers:\n",
    "        x = keras.layers.Dense(units, activation='relu')(x)\n",
    "\n",
    "    # Latent space\n",
    "    latent_mean = keras.layers.Dense(latent_dims, activation=None)(x)\n",
    "    latent_log_variance = keras.layers.Dense(latent_dims, activation=None)(x)\n",
    "\n",
    "    # Reparameterization trick\n",
    "    def sampling(args):\n",
    "        latent_mean, latent_log_variance = args\n",
    "        epsilon = keras.backend.random_normal(shape=(keras.backend.shape(latent_mean)[0], latent_dims),\n",
    "                                              mean=0.0, stddev=0.1)\n",
    "        return latent_mean + keras.backend.exp(latent_log_variance) * epsilon\n",
    "\n",
    "    latent_space = keras.layers.Lambda(sampling)([latent_mean, latent_log_variance])\n",
    "\n",
    "    # Decoder\n",
    "    decoder_inputs = keras.Input(shape=(latent_dims,))\n",
    "    x = decoder_inputs\n",
    "\n",
    "    for units in reversed(hidden_layers):\n",
    "        x = keras.layers.Dense(units, activation='relu')(x)\n",
    "\n",
    "    decoder_outputs = keras.layers.Dense(input_dims, activation='sigmoid')(x)\n",
    "\n",
    "    # Define encoder and decoder models\n",
    "    encoder = keras.Model(encoder_inputs, [latent_space, latent_mean, latent_log_variance], name='encoder')\n",
    "    decoder = keras.Model(decoder_inputs, decoder_outputs, name='decoder')\n",
    "\n",
    "    # Define full autoencoder model\n",
    "    autoencoder_outputs = decoder(encoder(encoder_inputs)[0])\n",
    "    autoencoder = keras.Model(encoder_inputs, autoencoder_outputs, name='autoencoder')\n",
    "\n",
    "    # Compile the autoencoder model\n",
    "    autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "    return encoder, decoder, autoencoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "tf.compat.v1.set_random_seed(0)\n",
    "encoder, decoder, auto = autoencoder(784, [512, 256], 2)\n",
    "if len(auto.layers) == 3:\n",
    "    print(auto.layers[0].input_shape == [(None, 784)])\n",
    "    print(auto.layers[1] is encoder)\n",
    "    print(auto.layers[2] is decoder)\n",
    "\n",
    "with open('1-test', 'w+') as f:\n",
    "    x_test = np.load(\"/home/ediddev/School Repos/holbertonschool-machine_learning/supervised_learning/data/MNIST.npz\")[\"X_test\"]\n",
    "    x_test = x_test[:256].reshape((-1, 784))\n",
    "    f.write(np.format_float_scientific(auto.evaluate(x_test, x_test, verbose=False), precision=6) + '\\n')\n",
    "    f.write(auto.optimizer.__class__.__name__ + '\\n')\n",
    "\n",
    "with open('2-test', 'w+') as f:\n",
    "    try:\n",
    "        f.write(encoder.layers[0].__class__.__name__ + '\\n')\n",
    "        f.write(str(encoder.layers[0].input_shape) + '\\n')\n",
    "    except:\n",
    "        f.write('FAIL\\n')\n",
    "    for layer in encoder.layers[1:]:\n",
    "        try:\n",
    "            f.write(layer.__class__.__name__ + '\\n')\n",
    "            if layer.__class__.__name__ == 'Dense':\n",
    "                if layer.activation != None:\n",
    "                    f.write(layer.activation.__name__ + '\\n')\n",
    "                f.write(str(layer.input_shape) + '\\n')\n",
    "                f.write(str(layer.output_shape) + '\\n')\n",
    "            elif layer.__class__.__name__ == 'Lambda':\n",
    "                assert(len(layer.input) == 2)\n",
    "                assert(encoder.layers[-3].output in layer.input)\n",
    "                assert(encoder.layers[-2].output in layer.input)\n",
    "                f.write(str(layer.input_shape) + '\\n')\n",
    "                f.write(str(layer.output_shape) + '\\n')\n",
    "        except:\n",
    "            f.write('FAIL\\n')\n",
    "\n",
    "with open('3-test', 'w+') as f:\n",
    "    try:\n",
    "        f.write(decoder.layers[0].__class__.__name__ + '\\n')\n",
    "        f.write(str(decoder.layers[0].input_shape) + '\\n')\n",
    "    except:\n",
    "        f.write('FAIL\\n')\n",
    "    for layer in decoder.layers[1:]:\n",
    "        try:\n",
    "            f.write(layer.__class__.__name__ + '\\n')\n",
    "            if layer.__class__.__name__ == 'Dense' and layer.activation != None:\n",
    "                f.write(layer.activation.__name__ + '\\n')\n",
    "            f.write(str(layer.input_shape) + '\\n')\n",
    "            f.write(str(layer.output_shape) + '\\n')\n",
    "        except:\n",
    "            f.write('FAIL\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
