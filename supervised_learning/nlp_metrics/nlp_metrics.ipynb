{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'ignore', 'over': 'warn', 'under': 'ignore', 'invalid': 'ignore'}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "np.seterr(divide='ignore', invalid='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Task 0: Unigram BLEU score\"\"\"\n",
    "\n",
    "\n",
    "def uni_bleu(references, sentence):\n",
    "    \"\"\"Calculates the unigram BLEU score for a sentence\n",
    "    Args:\n",
    "        references: list of reference translations\n",
    "            each ref translation is a list of the words in the translation\n",
    "        sentence: list containing the model proposed sentence\n",
    "    Returns:\n",
    "        the unigram BLEU score\"\"\"\n",
    "\n",
    "    # Calculating P\n",
    "    # Remove duplicates from sentence\n",
    "    seen = set()\n",
    "    unigrams = [x for x in sentence if not (x in seen or seen.add(x))]\n",
    "    print(unigrams)\n",
    "    # Count appearances in references and sentence for each unigram\n",
    "    sent_app = [sentence.count(i) for i in unigrams]\n",
    "    ref_app = []\n",
    "    for ref in references:\n",
    "        for word in unigrams:\n",
    "            if word in ref and word not in ref_app:\n",
    "                ref_app.append(word)\n",
    "    \n",
    "    # Calculate Precision\n",
    "    uni_len = len(ref_app)\n",
    "    sent_len = len(sentence)\n",
    "    P = uni_len / sent_len\n",
    "    # precision = []\n",
    "    # for i, uni in enumerate(sent_app):\n",
    "    #     try:\n",
    "    #         precision.append(int(uni) / ref_app[..., i].max())\n",
    "    #     except RuntimeWarning:\n",
    "    #         precision.append(0)\n",
    "    # precision = np.sum([v for v in precision if not math.isinf(v)]) / uni_len\n",
    "\n",
    "    # Calculate Brevity Penalty\n",
    "    BP = 1\n",
    "    closest_length = min(len(ref) for ref in references)\n",
    "    if sent_len < closest_length:\n",
    "        BP = np.exp(1 - (closest_length/sent_len))\n",
    "\n",
    "    return P * BP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['there', 'is', 'a', 'cat', 'here']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6549846024623855"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "references = [[\"the\", \"cat\", \"is\", \"on\", \"the\", \"mat\"],\n",
    "              [\"there\", \"is\", \"a\", \"cat\", \"on\", \"the\", \"mat\"]]\n",
    "sentence = [\"there\", \"is\", \"a\", \"cat\", \"here\"]\n",
    "uni_bleu(references=references, sentence=sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Task 1: N-gram BLEU score\"\"\"\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def ngram_bleu(references, sentence, n):\n",
    "    \"\"\"Calculated the BLEU score for a sentence using n-gram BLEU algorithm\n",
    "    Args:\n",
    "        references: list of reference translations\n",
    "            each ref translation is a list of the words in the translation\n",
    "        sentence: list containing the model proposed sentence\n",
    "        n: size of the n-gram to use for evaluation\n",
    "    Returns:\n",
    "        the n-gram BLEU score\"\"\"\n",
    "\n",
    "    n_grams = n_gram_generator(sentence, n)\n",
    "\n",
    "    # Calculate the precision for each n-gram\n",
    "    # Count appearances in sentence and references for each n-gram\n",
    "    sent_app = []\n",
    "    ref_app = [[] for ref in references]\n",
    "    for n_gram in n_grams:\n",
    "        sent_app.append(n_gram_appearance(n_gram, sentence))\n",
    "    for i, ref in enumerate(references):\n",
    "        for n_gram in n_grams:\n",
    "            ref_app[i].append(n_gram_appearance(n_gram, ref))\n",
    "\n",
    "    # Merge the counts of appearances in references for max appearance\n",
    "    ref_app_max = np.dstack(ref_app).max(axis=2)[0]\n",
    "\n",
    "    # Calculate Precision\n",
    "    P = np.sum(ref_app_max) / np.sum(sent_app)\n",
    "\n",
    "    # Calculate Brevity Penalty\n",
    "    BP = 1\n",
    "    sent_len = len(sentence)\n",
    "    closest_length = min(len(ref) for ref in references)\n",
    "    if sent_len < closest_length:\n",
    "        BP = np.exp(1 - (closest_length/sent_len))\n",
    "    return P * BP\n",
    "\n",
    "def n_gram_generator(sentence, n):\n",
    "    \"\"\"Generates a list of n-grams from a sentence\n",
    "    Args:\n",
    "        sentence: list containing the model proposed sentence\n",
    "        n: size of the n-gram to generate\n",
    "    Returns:\n",
    "        list of n-grams\"\"\"\n",
    "\n",
    "    n_grams = []\n",
    "    for i in range(len(sentence) - n + 1):\n",
    "        if sentence[i:i+n] not in n_grams:\n",
    "            n_grams.append(sentence[i:i+n])\n",
    "\n",
    "    return n_grams\n",
    "\n",
    "def n_gram_appearance(n_gram, sentence):\n",
    "    \"\"\"Counts the number of appearances of a n-gram in a sentence\n",
    "    Args:\n",
    "        n_gram: n-gram to search for\n",
    "        sentence: list containing the model proposed sentence\n",
    "    Returns:\n",
    "        number of appearances of n_gram in sentence\"\"\"\n",
    "\n",
    "    count = 0\n",
    "    for i in range(len(sentence) - len(n_gram) + 1):\n",
    "        if sentence[i:i+len(n_gram)] == n_gram:\n",
    "            count += 1\n",
    "\n",
    "    return count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6140480648084865\n"
     ]
    }
   ],
   "source": [
    "references = [[\"the\", \"cat\", \"is\", \"on\", \"the\", \"mat\"], [\"there\", \"is\", \"a\", \"cat\", \"on\", \"the\", \"mat\"]]\n",
    "sentence = [\"there\", \"is\", \"a\", \"cat\", \"here\"]\n",
    "\n",
    "print(ngram_bleu(references, sentence, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Task 2: Cumulative N-gram BLEU score\"\"\"\n",
    "\n",
    "\n",
    "def cumulative_bleu(references, sentence, n):\n",
    "    \"\"\"Calculates the cumulative n-gram BLEU score for a sentence\n",
    "    Args:\n",
    "        references: list of reference translations\n",
    "        sentence: list containing the model proposed sentence\n",
    "        n: size of the largest n-gram to use\n",
    "    Returns:\n",
    "        the cumulative n-gram BLEU score\"\"\"\n",
    "\n",
    "    # Calculate the precision for each n-gram size\n",
    "    precisions = []\n",
    "    for i in range(1, n + 1):\n",
    "        precisions.append(np.log(precision(references, sentence, i)))\n",
    "    P = np.exp(np.sum(precisions) / n)\n",
    "\n",
    "    # Calculate Brevity Penalty\n",
    "    BP = 1\n",
    "    sent_len = len(sentence)\n",
    "    closest_length = min(len(ref) for ref in references)\n",
    "    if sent_len < closest_length:\n",
    "        BP = np.exp(1 - (closest_length/sent_len))\n",
    "    return P * BP\n",
    "\n",
    "def n_gram_generator(sentence, n):\n",
    "    \"\"\"Generates a list of n-grams from a sentence\n",
    "    Args:\n",
    "        sentence: list containing the model proposed sentence\n",
    "        n: size of the n-gram to generate\n",
    "    Returns:\n",
    "        list of n-grams\"\"\"\n",
    "\n",
    "    n_grams = []\n",
    "    for i in range(len(sentence) - n + 1):\n",
    "        if sentence[i:i+n] not in n_grams:\n",
    "            n_grams.append(sentence[i:i+n])\n",
    "\n",
    "    return n_grams\n",
    "\n",
    "def n_gram_appearance(n_gram, sentence):\n",
    "    \"\"\"Counts the number of appearances of a n-gram in a sentence\n",
    "    Args:\n",
    "        n_gram: n-gram to search for\n",
    "        sentence: list containing the model proposed sentence\n",
    "    Returns:\n",
    "        number of appearances of n_gram in sentence\"\"\"\n",
    "\n",
    "    count = 0\n",
    "    for i in range(len(sentence) - len(n_gram) + 1):\n",
    "        if sentence[i:i+len(n_gram)] == n_gram:\n",
    "            count += 1\n",
    "\n",
    "    return count\n",
    "\n",
    "def precision(references, sentence, n):\n",
    "    \"\"\"Calculates the precision for a sentence and a n-gram value\n",
    "    Args:\n",
    "        references: list of reference translations\n",
    "        sentence: list containing the model proposed sentence\n",
    "        n: size of the n-gram to use\n",
    "    Returns:\n",
    "        precision score\"\"\"\n",
    "\n",
    "    n_grams = n_gram_generator(sentence, n)\n",
    "\n",
    "    # Calculate the precision for each n-gram\n",
    "    # Count appearances in sentence and references for each n-gram\n",
    "    sent_app = []\n",
    "    ref_app = [[] for ref in references]\n",
    "    for n_gram in n_grams:\n",
    "        sent_app.append(n_gram_appearance(n_gram, sentence))\n",
    "    for i, ref in enumerate(references):\n",
    "        for n_gram in n_grams:\n",
    "            ref_app[i].append(n_gram_appearance(n_gram, ref))\n",
    "\n",
    "    # Merge the counts of appearances in references for max appearance\n",
    "    ref_app_max = np.dstack(ref_app).max(axis=2)[0]\n",
    "\n",
    "    # Calculate Precision\n",
    "    P = np.sum(ref_app_max) / np.sum(sent_app)\n",
    "\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5475182535069453\n"
     ]
    }
   ],
   "source": [
    "references = [[\"the\", \"cat\", \"is\", \"on\", \"the\", \"mat\"], [\"there\", \"is\", \"a\", \"cat\", \"on\", \"the\", \"mat\"]]\n",
    "sentence = [\"there\", \"is\", \"a\", \"cat\", \"here\"]\n",
    "\n",
    "print(cumulative_bleu(references, sentence, 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
