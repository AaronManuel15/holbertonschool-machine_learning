{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-21 09:35:08.558691: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-21 09:35:09.025284: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-21 09:35:10.506636: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2023-04-21 09:35:10.507299: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2023-04-21 09:35:10.507314: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import glob\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Yolo:\n",
    "    \"\"\"Uses You only look once (YOLO)v3 to perform object detection\n",
    "    Args:\n",
    "        model_path: path to where a Darknet Keras model is stored\n",
    "        classes_path: path to where the list of class names used for the Darknet model, listed in order of index, can be found\n",
    "        class_t: float representing the box score threshold for the initial filtering step\n",
    "        nms_t: float representing the IOU threshold for non-max suppression\n",
    "        anchors: numpy.ndarray of shape (outputs, anchor_boxes, 2) containing all of the anchor boxes:\n",
    "            outputs is the number of outputs (predictions) made by the Darknet model\n",
    "            anchor_boxes is the number of anchor boxes used for each prediction\n",
    "            2 => [anchor_box_width, anchor_box_height]\n",
    "    \"\"\"\n",
    "    def __init__(self, model_path, classes_path, class_t, nms_t, anchors):\n",
    "        \"\"\"Initializes the Yolo class\"\"\"\n",
    "        self.model = load_model(model_path)\n",
    "        with open(classes_path) as f:\n",
    "            self.class_names = [line.strip() for line in f]\n",
    "        self.class_t = class_t\n",
    "        self.nms_t = nms_t\n",
    "        self.anchors = anchors\n",
    "\n",
    "    def process_outputs(self, outputs, image_size):\n",
    "        \"\"\"Process Darknet model outputs\n",
    "        Args:\n",
    "            outputs: list of numpy.ndarrays containing the predictions from\n",
    "                the Darknet model for a single image:\n",
    "                Each output will have the shape (grid_height, grid_width,\n",
    "                    anchor_boxes, 4 + 1 + classes)\n",
    "                    grid_height & grid_width => the height and width of the\n",
    "                        grid used for the output\n",
    "                    anchor_boxes => the number of anchor boxes used\n",
    "                    4 => (t_x, t_y, t_w, t_h)\n",
    "                    1 => box_confidence\n",
    "                    classes => class probabilities for all classes\n",
    "            image_size: numpy.ndarray containing the image’s original size\n",
    "                [image_height, image_width]\n",
    "        Returns:\n",
    "            A tuple of (boxes, box_confidences, box_class_probs):\n",
    "                boxes: a list of numpy.ndarrays of shape (grid_height,\n",
    "                    grid_width, anchor_boxes, 4) containing the processed\n",
    "                    boundary boxes for each output, respectively:\n",
    "                    4 => (x1, y1, x2, y2)\n",
    "                        (x1, y1, x2, y2) should represent the boundary box\n",
    "                        relative to original image\n",
    "                box_confidences: a list of numpy.ndarrays of shape (grid_height,\n",
    "                    grid_width, anchor_boxes, 1) containing the box confidences\n",
    "                    for each output, respectively\n",
    "                box_class_probs: a list of numpy.ndarrays of shape (grid_height,\n",
    "                    grid_width, anchor_boxes, classes) containing the box’s\n",
    "                    class probabilities for each output, respectively\n",
    "        \"\"\"\n",
    "        boxes = []\n",
    "        box_confidences = []\n",
    "        box_class_probs = []\n",
    "        for i in range(len(outputs)):\n",
    "            boxes.append(outputs[i][..., :4])\n",
    "            box_confidences.append(1 / (1 + np.exp(-outputs[i][..., 4:5])))\n",
    "            box_class_probs.append(1 / (1 + np.exp(-outputs[i][..., 5:])))\n",
    "        image_height, image_width = image_size\n",
    "        for i in range(len(boxes)):\n",
    "            grid_height = outputs[i].shape[0]\n",
    "            grid_width = outputs[i].shape[1]\n",
    "            anchor_boxes = outputs[i].shape[2]\n",
    "            for cy in range(grid_height):\n",
    "                for cx in range(grid_width):\n",
    "                    for b in range(anchor_boxes):\n",
    "                        tx, ty, tw, th = boxes[i][cy, cx, b]\n",
    "                        pw, ph = self.anchors[i][b]\n",
    "                        bx = (1 / (1 + np.exp(-tx))) + cx\n",
    "                        by = (1 / (1 + np.exp(-ty))) + cy\n",
    "                        bw = pw * np.exp(tw)\n",
    "                        bh = ph * np.exp(th)\n",
    "                        bx /= grid_width\n",
    "                        by /= grid_height\n",
    "                        bw /= self.model.input.shape[1]\n",
    "                        bh /= self.model.input.shape[2]\n",
    "                        x1 = (bx - (bw / 2)) * image_width\n",
    "                        y1 = (by - (bh / 2)) * image_height\n",
    "                        x2 = (bx + (bw / 2)) * image_width\n",
    "                        y2 = (by + (bh / 2)) * image_height\n",
    "                        boxes[i][cy, cx, b] = [x1, y1, x2, y2]\n",
    "        return (boxes, box_confidences, box_class_probs)\n",
    "    \n",
    "    def filter_boxes(self, boxes, box_confidences, box_class_probs):\n",
    "        \"\"\"Removes the boxes with low box scores\n",
    "        Args:\n",
    "            boxes: list of numpy.ndarrays of shape (grid_height, grid_width,\n",
    "                anchor_boxes, 4) containing the processed boundary boxes for\n",
    "                each output, respectively\n",
    "            box_confidences: list of numpy.ndarrays of shape (grid_height,\n",
    "                grid_width, anchor_boxes, 1) containing the processed box\n",
    "                confidences for each output, respectively\n",
    "            box_class_probs: list of numpy.ndarrays of shape (grid_height,\n",
    "                grid_width, anchor_boxes, classes) containing the processed\n",
    "                box class probabilities for each output, respectively\n",
    "        Returns:\n",
    "            A tuple of (filtered_boxes, box_classes, box_scores):\n",
    "                filtered_boxes: a numpy.ndarray of shape (?, 4) containing all\n",
    "                    of the filtered bounding boxes:\n",
    "                box_classes: a numpy.ndarray of shape (?,) containing the class\n",
    "                    number that each box in filtered_boxes predicts\n",
    "                box_scores: a numpy.ndarray of shape (?) containing the box\n",
    "                    scores\"\"\"\n",
    "        filtered_boxes, box_classes, box_scores = None, [], []\n",
    "        for i in range(len(boxes)):\n",
    "            cur_box_score = box_confidences[i] * box_class_probs[i]\n",
    "            cur_box_class = np.argmax(cur_box_score, axis=-1)\n",
    "            cur_box_score = np.max(cur_box_score, axis=-1)\n",
    "            mask = cur_box_score >= self.class_t\n",
    "            if filtered_boxes is None:\n",
    "                filtered_boxes = boxes[i][mask]\n",
    "                box_scores = cur_box_score[mask]\n",
    "                box_classes = cur_box_class[mask]\n",
    "            else:\n",
    "                filtered_boxes = np.concatenate((filtered_boxes,\n",
    "                                                 boxes[i][mask]),\n",
    "                                                axis=0)\n",
    "                box_classes = np.concatenate((box_classes,\n",
    "                                                 cur_box_class[mask]),\n",
    "                                                axis=0)\n",
    "                box_scores = np.concatenate((box_scores,\n",
    "                                                 cur_box_score[mask]),\n",
    "                                                axis=0)\n",
    "        return (filtered_boxes, box_classes, box_scores)\n",
    "\n",
    "    def iou(self, box1, box2):\n",
    "        \"\"\"Method to calculate the Intersection over Union\n",
    "        Args:\n",
    "            box1: first box\n",
    "            box2: second box\n",
    "        Returns:\n",
    "            the Intersection over Union of the two boxes\n",
    "        \"\"\"\n",
    "        x1, y1, x2, y2 = box1[1]\n",
    "        x3, y3, x4, y4 = box2\n",
    "        xi1 = max(x1, x3)\n",
    "        yi1 = max(y1, y3)\n",
    "        xi2 = min(x2, x4)\n",
    "        yi2 = min(y2, y4)\n",
    "        inter_area = max(yi2 - yi1, 0) * max(xi2 - xi1, 0)\n",
    "        box1_area = (y2 - y1) * (x2 - x1)\n",
    "        box2_area = (y4 - y3) * (x4 - x3)\n",
    "        union_area = box1_area + box2_area - inter_area\n",
    "        return inter_area / union_area\n",
    "\n",
    "    def non_max_suppression(self, filtered_boxes, box_classes, box_scores):\n",
    "        box_predictions = []\n",
    "        predicted_box_classes = []\n",
    "        predicted_box_scores = []\n",
    "\n",
    "        for c in set(box_classes):\n",
    "            idxs = np.where(box_classes == c)\n",
    "            class_boxes = filtered_boxes[idxs]\n",
    "            class_box_scores = box_scores[idxs]\n",
    "\n",
    "            while len(class_boxes) > 0:\n",
    "                max_idx = np.argmax(class_box_scores)\n",
    "                box_predictions.append(class_boxes[max_idx])\n",
    "                predicted_box_classes.append(c)\n",
    "                predicted_box_scores.append(class_box_scores[max_idx])\n",
    "\n",
    "                class_boxes = np.delete(class_boxes, max_idx, axis=0)\n",
    "                class_box_scores = np.delete(class_box_scores, max_idx, axis=0)\n",
    "\n",
    "                if len(class_boxes) == 0:\n",
    "                    break\n",
    "\n",
    "                iou = self.intersection_over_union(box_predictions[-1],\n",
    "                                                   class_boxes)\n",
    "                iou_mask = iou < self.nms_t\n",
    "\n",
    "                class_boxes = class_boxes[iou_mask]\n",
    "                class_box_scores = class_box_scores[iou_mask]\n",
    "\n",
    "        return (np.array(box_predictions),\n",
    "                np.array(predicted_box_classes),\n",
    "                np.array(predicted_box_scores))\n",
    "\n",
    "    def intersection_over_union(self, box1, boxes):\n",
    "        x1 = np.maximum(box1[0], boxes[:, 0])\n",
    "        y1 = np.maximum(box1[1], boxes[:, 1])\n",
    "        x2 = np.minimum(box1[2], boxes[:, 2])\n",
    "        y2 = np.minimum(box1[3], boxes[:, 3])\n",
    "\n",
    "        intersection_area = np.maximum(x2 - x1, 0) * np.maximum(y2 - y1, 0)\n",
    "\n",
    "        box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "        boxes_area = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])\n",
    "\n",
    "        union_area = box1_area + boxes_area - intersection_area\n",
    "\n",
    "        return intersection_area / union_area\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_images(folder_path):\n",
    "        \"\"\"Loads images from a filepath\n",
    "        Args:\n",
    "            folder_path: a string representing the path to the folder holding\n",
    "                all the images to load\n",
    "        Returns:\n",
    "            a tuple of (images, image_paths):\n",
    "                images: a list of images as numpy.ndarrays\n",
    "                image_paths: a list of paths to the individual images in images\n",
    "        \"\"\"\n",
    "        image_paths = glob.glob(folder_path + '/*')\n",
    "        images = [cv2.imread(image) for image in image_paths]\n",
    "        return images, image_paths\n",
    "\n",
    "    def preprocess_images(self, images):\n",
    "        \"\"\"Resizes and Rescales the images to fit the model requirements\n",
    "        Args:\n",
    "            images: a list of images as numpy.ndarrays\n",
    "        Returns:\n",
    "            a tuple of (pimages, image_shapes):\n",
    "                pimages: a numpy.ndarray of shape (ni, input_h, input_w, 3)\n",
    "                    containing all of the preprocessed images\n",
    "                    - ni: the number of images that were preprocessed\n",
    "                    - input_h: the input height for the Darknet model\n",
    "                    - input_w: the input width for the Darknet model\n",
    "                    - 3: number of color channels\n",
    "                image_shapes: a numpy.ndarray of shape (ni, 2) containing the\n",
    "                    original height and width of the images\n",
    "                    - ni: the number of images that were preprocessed\n",
    "        \"\"\"\n",
    "        pimages = []\n",
    "        image_shapes = []\n",
    "        for image in images:\n",
    "            image_shapes.append(image.shape[:2])\n",
    "            image = cv2.resize(image, (self.model.input.shape[1],\n",
    "                                       self.model.input.shape[2]),\n",
    "                               interpolation=cv2.INTER_CUBIC)\n",
    "            image = image / 255\n",
    "            pimages.append(image)\n",
    "        return (np.array(pimages), np.array(image_shapes))\n",
    "    \n",
    "    def show_boxes(self, image, boxes, box_classes, box_scores, file_name):\n",
    "        \"\"\"Shows image with all boundary boxes, class names, and box scores\n",
    "        Args:\n",
    "            image: a numpy.ndarray containing an unprocessed image\n",
    "            boxes: a numpy.ndarray containing the boundary boxes for the image\n",
    "            box_classes: a numpy.ndarray containing the class indices for each\n",
    "                box\n",
    "            box_scores: a numpy.ndarray containing the box scores for each box\n",
    "            file_name: the file path where the original image is stored\"\"\"\n",
    "        for i, box in enumerate(boxes):\n",
    "            x1, y1, x2, y2 = box\n",
    "            cv2.rectangle(image, (int(x1), int(y1)), (int(x2), int(y2)),\n",
    "                          (255, 0, 0), 2)\n",
    "            cv2.putText(image, self.class_names[box_classes[i]] + ' ' +\n",
    "                        \"{:.2f}\".format(box_scores[i]),\n",
    "                        (int(x1-1), int(y1-5)), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                        (0, 0, 255), 1, lineType=cv2.LINE_AA)\n",
    "        cv2.imshow(file_name, image)\n",
    "        print(\"Press 's'\")\n",
    "        key = cv2.waitKey(0)\n",
    "        if key == ord('s'):\n",
    "            if os.path.isdir(\"./detections\") is False:\n",
    "                os.mkdir(\"./detections\")\n",
    "            cv2.imwrite(\"./detections/{}\".format(file_name), image)\n",
    "        del key\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "    def predict(self, folder_path):\n",
    "        \"\"\"Displays all images using the show_boxes method\n",
    "        Args:\n",
    "            folder_path: a string representing the path to the folder holding\n",
    "                all the images to predict\n",
    "        Returns:\n",
    "            A tuple of (predictions, image_paths):\n",
    "                predictions: list of tuples for each image of\n",
    "                    (boxes, box_classes, box_scores)\n",
    "                image_paths: list of image paths corresponding to each\n",
    "                    prediction in predictions\n",
    "        \"\"\"\n",
    "        images, image_paths = self.load_images(folder_path)\n",
    "        pimages, image_shapes = self.preprocess_images(images)\n",
    "        outputs = self.model.predict(pimages)\n",
    "        predictions = []\n",
    "        for i, image in enumerate(images):\n",
    "            three_out = [\n",
    "                outputs[0][i], outputs[1][i], outputs[2][i]\n",
    "            ]\n",
    "            boxes, box_classes, box_scores = self.process_outputs(three_out,\n",
    "                                                                  image_shapes[i])\n",
    "            boxes, box_classes, box_scores = self.filter_boxes(boxes,\n",
    "                                                               box_scores,\n",
    "                                                               box_classes)\n",
    "            boxes, box_classes, box_scores = self.non_max_suppression(boxes,\n",
    "                                                                      box_classes,\n",
    "                                                                      box_scores)\n",
    "            predictions.append((boxes, box_classes, box_scores))\n",
    "            self.show_boxes(image, boxes, box_classes, box_scores,\n",
    "                            image_paths[i].split('/')[-1])\n",
    "        return (predictions, image_paths)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 0 testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "anchors = np.array([[[116, 90], [156, 198], [373, 326]],\n",
    "                    [[30, 61], [62, 45], [59, 119]],\n",
    "                    [[10, 13], [16, 30], [33, 23]]])\n",
    "yolo = Yolo('../data/yolo.h5', '../data/coco_classes.txt', 0.6, 0.5, anchors)\n",
    "yolo.model.summary()\n",
    "print('Class names:', yolo.class_names)\n",
    "print('Class threshold:', yolo.class_t)\n",
    "print('NMS threshold:', yolo.nms_t)\n",
    "print('Anchor boxes:', yolo.anchors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "anchors = np.array([[[116, 90], [156, 198], [373, 326]],\n",
    "                    [[30, 61], [62, 45], [59, 119]],\n",
    "                    [[10, 13], [16, 30], [33, 23]]])\n",
    "yolo = Yolo('../data/yolo.h5', '../data/coco_classes.txt', 0.6, 0.5, anchors)\n",
    "output1 = np.random.randn(13, 13, 3, 85)\n",
    "output2 = np.random.randn(26, 26, 3, 85)\n",
    "output3 = np.random.randn(52, 52, 3, 85)\n",
    "boxes, box_confidences, box_class_probs = yolo.process_outputs([output1, output2, output3], np.array([500, 700]))\n",
    "print('Boxes:', boxes)\n",
    "print('Box confidences:', box_confidences)\n",
    "print('Box class probabilities:', box_class_probs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "anchors = np.array([[[116, 90], [156, 198], [373, 326]],\n",
    "                    [[30, 61], [62, 45], [59, 119]],\n",
    "                    [[10, 13], [16, 30], [33, 23]]])\n",
    "yolo = Yolo('../data/yolo.h5', '../data/coco_classes.txt', 0.6, 0.5, anchors)\n",
    "output1 = np.random.randn(13, 13, 3, 85)\n",
    "output2 = np.random.randn(26, 26, 3, 85)\n",
    "output3 = np.random.randn(52, 52, 3, 85)\n",
    "boxes, box_confidences, box_class_probs = yolo.process_outputs([output1, output2, output3], np.array([500, 700]))\n",
    "boxes, box_classes, box_scores = yolo.filter_boxes(boxes, box_confidences, box_class_probs)\n",
    "print('Boxes:', boxes)\n",
    "print('Box classes:', box_classes)\n",
    "print('Box scores:', box_scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "anchors = np.array([[[116, 90], [156, 198], [373, 326]],\n",
    "                    [[30, 61], [62, 45], [59, 119]],\n",
    "                    [[10, 13], [16, 30], [33, 23]]])\n",
    "yolo = Yolo('../data/yolo.h5', '../data/coco_classes.txt', 0.6, 0.5, anchors)\n",
    "output1 = np.random.randn(13, 13, 3, 85)\n",
    "output2 = np.random.randn(26, 26, 3, 85)\n",
    "output3 = np.random.randn(52, 52, 3, 85)\n",
    "boxes, box_confidences, box_class_probs = yolo.process_outputs([output1, output2, output3], np.array([500, 700]))\n",
    "boxes, box_classes, box_scores = yolo.filter_boxes(boxes, box_confidences, box_class_probs)\n",
    "boxes, box_classes, box_scores = yolo.non_max_suppression(boxes, box_classes, box_scores)\n",
    "print('Boxes:', boxes)\n",
    "print('Box classes:', box_classes)\n",
    "print('Box scores:', box_scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "anchors = np.array([[[116, 90], [156, 198], [373, 326]],\n",
    "                    [[30, 61], [62, 45], [59, 119]],\n",
    "                    [[10, 13], [16, 30], [33, 23]]])\n",
    "yolo = Yolo('../data/yolo.h5', '../data/coco_classes.txt', 0.6, 0.5, anchors)\n",
    "images, image_paths = yolo.load_images('../data/yolo')\n",
    "i = np.random.randint(0, len(images))\n",
    "cv2.imshow(image_paths[i], images[i])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "anchors = np.array([[[116, 90], [156, 198], [373, 326]],\n",
    "                    [[30, 61], [62, 45], [59, 119]],\n",
    "                    [[10, 13], [16, 30], [33, 23]]])\n",
    "yolo = Yolo('../data/yolo.h5', '../data/coco_classes.txt', 0.6, 0.5, anchors)\n",
    "images, image_paths = yolo.load_images('../data/yolo')\n",
    "pimages, image_shapes = yolo.preprocess_images(images)\n",
    "print(type(pimages), pimages.shape)\n",
    "print(type(image_shapes), image_shapes.shape)\n",
    "i = np.random.randint(0, len(images))\n",
    "print(images[i].shape, ':', image_shapes[i])\n",
    "cv2.imshow(image_paths[i], pimages[i])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "0 ../data/yolo/horses.jpg\n",
      "1 ../data/yolo/takagaki.jpg\n",
      "2 ../data/yolo/dog.jpg\n",
      "Press 's'\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "anchors = np.array([[[116, 90], [156, 198], [373, 326]],\n",
    "                    [[30, 61], [62, 45], [59, 119]],\n",
    "                    [[10, 13], [16, 30], [33, 23]]])\n",
    "yolo = Yolo('../data/yolo.h5', '../data/coco_classes.txt', 0.6, 0.5, anchors)\n",
    "images, image_paths = yolo.load_images('../data/yolo')\n",
    "boxes = np.array([[119.22100287, 118.62197718, 567.75985556, 440.44121152],\n",
    "                  [468.53530752, 84.48338278, 696.04923556, 167.98947829],\n",
    "                  [124.2043716, 220.43365057, 319.4254314 , 542.13706101]])\n",
    "box_scores = np.array([0.99537075, 0.91536146, 0.9988506])\n",
    "box_classes = np.array([1, 7, 16])\n",
    "ind = 0\n",
    "for i, name in enumerate(image_paths):\n",
    "    print(i, name)\n",
    "    if \"dog.jpg\" in name:\n",
    "        ind = i\n",
    "        break\n",
    "yolo.show_boxes(images[i], boxes, box_classes, box_scores, \"dog.jpg\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-21 10:50:39.023057: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ediddev/.local/lib/python3.8/site-packages/cv2/../../lib64:/usr/local/cuda/lib64:\n",
      "2023-04-21 10:50:39.023501: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-04-21 10:50:39.023744: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (BOBO-CODE): /proc/driver/nvidia/version does not exist\n",
      "2023-04-21 10:50:39.026762: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "Press 's'\n",
      "Press 's'\n",
      "Press 's'\n",
      "Press 's'\n",
      "Press 's'\n",
      "Press 's'\n",
      "../data/yolo/dog.jpg\n",
      "(array([[124.10596, 220.4373 , 319.45682, 542.3967 ],\n",
      "       [119.10174, 118.63829, 567.89417, 440.58704],\n",
      "       [468.6808 ,  84.4819 , 695.9741 , 168.00749]], dtype=float32), array([16,  1,  7]), array([0.99883264, 0.9954546 , 0.91439855], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "anchors = np.array([[[116, 90], [156, 198], [373, 326]],\n",
    "                    [[30, 61], [62, 45], [59, 119]],\n",
    "                    [[10, 13], [16, 30], [33, 23]]])\n",
    "yolo = Yolo('../data/yolo.h5', '../data/coco_classes.txt', 0.6, 0.5, anchors)\n",
    "predictions, image_paths = yolo.predict('../data/yolo')\n",
    "for i, name in enumerate(image_paths):\n",
    "    if \"dog.jpg\" in name:\n",
    "        ind = i\n",
    "        break\n",
    "print(image_paths[ind])\n",
    "print(predictions[ind])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
